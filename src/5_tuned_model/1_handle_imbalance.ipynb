{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0643d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874cf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = first_run\n",
    "except NameError:\n",
    "    first_run = True\n",
    "    os.chdir(os.getcwd().rsplit(\"/\", 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c28e2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d99414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = joblib.load(\"../data/train/preprocessed/train_features_labels.joblib.gz\")\n",
    "\n",
    "X_validation, y_validation = joblib.load(\"../data/train/preprocessed/validation_features_labels.joblib.gz\")"
   ]
  },
  {
   "source": [
    "# Hold your SMOTE for a minute\n",
    "\n",
    "SMOTE has become a ubiquitous way to handle imbalanced classes by oversampling the minority class. However, the fact that many of our features have low variance due to a lot of zero values, generating artificial samples from them can actually become quite counterproductive. Thus, we will experiment with both SMOTE and a custom undersampler that tries to capture most of the variance of the majority class. Whichever strategy yields better results for our baseline model will be the one we move forward with."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Custom undersampler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryUndersampler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(X: np.ndarray, y: np.ndarray):\n",
    "        self.minority_class = pd.value_counts(pd.Series(y)).index[-1]\n",
    "        self.folds = folds = math.floor(X.shape[0] / np.sum(y==self.minority_class))\n",
    "        self.kfold = KFold(self.folds, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "name": "python388jvsc74a57bd09f119b1d3a8a63730ae7ee508102d23a56b995c1f2248036bd772c0398b7d40e",
   "display_name": "Python 3.8.8 64-bit ('klarna': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}