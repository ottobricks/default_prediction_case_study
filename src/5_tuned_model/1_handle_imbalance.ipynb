{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ef8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f91c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = first_run\n",
    "except NameError:\n",
    "    first_run = True\n",
    "    os.chdir(os.getcwd().rsplit(\"/\", 1)[0])\n",
    "    from _aux import ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676e945",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb40eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = joblib.load(\n",
    "    \"../data/train/preprocessed/train_features_labels.joblib.gz\"\n",
    ")\n",
    "\n",
    "X_validation, y_validation = joblib.load(\n",
    "    \"../data/train/preprocessed/validation_features_labels.joblib.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2cf912",
   "metadata": {},
   "source": [
    "# Hold your SMOTE for a moment\n",
    "\n",
    "SMOTE has become a ubiquitous way to handle imbalanced classes by oversampling the minority class. However, the fact that many of our features have low variance due to a lot of zero values, generating artificial samples from them can actually become quite counterproductive. Thus, we will experiment with both SMOTE and a custom undersampler that tries to capture most of the variance of the majority class. Whichever strategy yields better results for our baseline model will be the one we move forward with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd135f3b",
   "metadata": {},
   "source": [
    "### 1. Custom undersampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0bd387",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5131495516149959 5.691116837902434 True\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    X_train_maj,\n",
    "    y_train_maj,\n",
    "    sample_variance,\n",
    "    sample_variance_zscore,\n",
    "    is_significant,\n",
    ") = ml.BinaryUndersampler(n_iterations=1_000).fit(X_train, y_train)\n",
    "print(sample_variance, sample_variance_zscore, is_significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bded84",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    816\n",
       "0.0    811\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Create new training set\n",
    "X_train_undersample = np.concatenate((X_train_maj, X_train[y_train == 1]))\n",
    "y_train_undersample = np.concatenate((y_train_maj, y_train[y_train == 1]))\n",
    "\n",
    "# Save the new trainig set\n",
    "joblib.dump(\n",
    "    [X_train_undersample, y_train_undersample],\n",
    "    \"../data/train/preprocessed/undersampled_train_features_labels.joblib.gz\",\n",
    ")\n",
    "\n",
    "# Check class balance\n",
    "pd.Series(y_train_undersample).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945dc166",
   "metadata": {},
   "source": [
    "As we can see, classes are almost equally matched. Hopefully, our stategy will improve the baseline performance, as the new sample catches an extremely high amount of variance if compared to bootstrap results. Let the drums roll..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34910db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = RandomForestClassifier().fit(X_train_undersample, y_train_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fcbb58",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    threshold     tn    fp   fn   tp  precision    recall        f1\n",
       "10       0.55  10962  3220   55  159   0.047055  0.742991  0.088505\n",
       "11       0.60  11191  2991   57  157   0.049873  0.733645  0.093397\n",
       "12       0.65  11812  2370   73  141   0.056153  0.658879  0.103486\n",
       "13       0.70  12431  1751   82  132   0.070101  0.616822  0.125894\n",
       "14       0.75  12657  1525   93  121   0.073512  0.565421  0.130108\n",
       "15       0.80  13032  1150  109  105   0.083665  0.490654  0.142954\n",
       "16       0.85  13311   871  116   98   0.101135  0.457944  0.165680\n",
       "17       0.90  13540   642  134   80   0.110803  0.373832  0.170940\n",
       "18       0.95  13725   457  146   68   0.129524  0.317757  0.184032"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>threshold</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>0.55</td>\n      <td>10962</td>\n      <td>3220</td>\n      <td>55</td>\n      <td>159</td>\n      <td>0.047055</td>\n      <td>0.742991</td>\n      <td>0.088505</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.60</td>\n      <td>11191</td>\n      <td>2991</td>\n      <td>57</td>\n      <td>157</td>\n      <td>0.049873</td>\n      <td>0.733645</td>\n      <td>0.093397</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.65</td>\n      <td>11812</td>\n      <td>2370</td>\n      <td>73</td>\n      <td>141</td>\n      <td>0.056153</td>\n      <td>0.658879</td>\n      <td>0.103486</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.70</td>\n      <td>12431</td>\n      <td>1751</td>\n      <td>82</td>\n      <td>132</td>\n      <td>0.070101</td>\n      <td>0.616822</td>\n      <td>0.125894</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.75</td>\n      <td>12657</td>\n      <td>1525</td>\n      <td>93</td>\n      <td>121</td>\n      <td>0.073512</td>\n      <td>0.565421</td>\n      <td>0.130108</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.80</td>\n      <td>13032</td>\n      <td>1150</td>\n      <td>109</td>\n      <td>105</td>\n      <td>0.083665</td>\n      <td>0.490654</td>\n      <td>0.142954</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.85</td>\n      <td>13311</td>\n      <td>871</td>\n      <td>116</td>\n      <td>98</td>\n      <td>0.101135</td>\n      <td>0.457944</td>\n      <td>0.165680</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.90</td>\n      <td>13540</td>\n      <td>642</td>\n      <td>134</td>\n      <td>80</td>\n      <td>0.110803</td>\n      <td>0.373832</td>\n      <td>0.170940</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.95</td>\n      <td>13725</td>\n      <td>457</td>\n      <td>146</td>\n      <td>68</td>\n      <td>0.129524</td>\n      <td>0.317757</td>\n      <td>0.184032</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "predictions = baseline.predict_proba(X_validation)\n",
    "\n",
    "threshold_perf = pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            threshold,\n",
    "            *confusion_matrix(\n",
    "                y_validation, (predictions[:, 1] > threshold).astype(int)\n",
    "            ).ravel(),\n",
    "        )\n",
    "        for threshold in np.arange(0.05, 1, 0.05)\n",
    "    ],\n",
    "    columns=[\"threshold\", \"tn\", \"fp\", \"fn\", \"tp\"],\n",
    ").assign(\n",
    "    precision=lambda df: df[\"tp\"] / (df[\"tp\"] + df[\"fp\"]),\n",
    "    recall=lambda df: df[\"tp\"] / (df[\"tp\"] + df[\"fn\"]),\n",
    "    f1=lambda df: 2\n",
    "    * (df[\"precision\"] * df[\"recall\"])\n",
    "    / (df[\"precision\"] + df[\"recall\"]),\n",
    ")\n",
    "\n",
    "threshold_perf.to_csv(\"../ml_artifacts/baseline2_model_performance.csv\", index=False)\n",
    "\n",
    "threshold_perf.query(\"threshold > .5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2a430",
   "metadata": {},
   "source": [
    "Honestly, these results are better than what we had expected. As we move the threshold, we can the the \"precision-recall\" trade-off take place. However, note that the F1 score does continually improve, which is a sympton of the fact that the trade-off is not perfectly squred in this case -- as it rarely is.\n",
    "\n",
    "Make no mistake, these are not good prediction results by any stretch of the imagination. Nevertheless, they do suggest that our strategy is successfull as baseline performance improved significantly with no change to the model, only the data changed. Let's compare them to the previous baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62bd09f1",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    threshold     tn  fp   fn  tp  precision    recall        f1\n",
       "10       0.55  14144  38  200  14   0.269231  0.065421  0.105263\n",
       "11       0.60  14157  25  201  13   0.342105  0.060748  0.103175\n",
       "12       0.65  14166  16  205   9   0.360000  0.042056  0.075314\n",
       "13       0.70  14173   9  207   7   0.437500  0.032710  0.060870\n",
       "14       0.75  14177   5  208   6   0.545455  0.028037  0.053333\n",
       "15       0.80  14180   2  209   5   0.714286  0.023364  0.045249\n",
       "16       0.85  14181   1  209   5   0.833333  0.023364  0.045455\n",
       "17       0.90  14181   1  210   4   0.800000  0.018692  0.036530"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>threshold</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>0.55</td>\n      <td>14144</td>\n      <td>38</td>\n      <td>200</td>\n      <td>14</td>\n      <td>0.269231</td>\n      <td>0.065421</td>\n      <td>0.105263</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.60</td>\n      <td>14157</td>\n      <td>25</td>\n      <td>201</td>\n      <td>13</td>\n      <td>0.342105</td>\n      <td>0.060748</td>\n      <td>0.103175</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.65</td>\n      <td>14166</td>\n      <td>16</td>\n      <td>205</td>\n      <td>9</td>\n      <td>0.360000</td>\n      <td>0.042056</td>\n      <td>0.075314</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.70</td>\n      <td>14173</td>\n      <td>9</td>\n      <td>207</td>\n      <td>7</td>\n      <td>0.437500</td>\n      <td>0.032710</td>\n      <td>0.060870</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.75</td>\n      <td>14177</td>\n      <td>5</td>\n      <td>208</td>\n      <td>6</td>\n      <td>0.545455</td>\n      <td>0.028037</td>\n      <td>0.053333</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.80</td>\n      <td>14180</td>\n      <td>2</td>\n      <td>209</td>\n      <td>5</td>\n      <td>0.714286</td>\n      <td>0.023364</td>\n      <td>0.045249</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.85</td>\n      <td>14181</td>\n      <td>1</td>\n      <td>209</td>\n      <td>5</td>\n      <td>0.833333</td>\n      <td>0.023364</td>\n      <td>0.045455</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.90</td>\n      <td>14181</td>\n      <td>1</td>\n      <td>210</td>\n      <td>4</td>\n      <td>0.800000</td>\n      <td>0.018692</td>\n      <td>0.036530</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pd.read_csv(\"../ml_artifacts/baseline_model_performance.csv\").query(\"threshold > .5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf269a",
   "metadata": {},
   "source": [
    "Contrary to what observed earlier, the F1 score drops as we move up the threshold, which is a symptom of the behaviour induced by the model. The model flags very little, which is good in the perpective of customer experience but at the cost of losing too much money for the company. In fact, such model doesn't even justify the cost of developing and maintaining it.\n",
    "\n",
    "As we get good results from our undersampling strategy and due to time constraints, we choose not to explore how SMOTE would perform at this time. Instead, we decide to allocate more time for hyperparameter tuning and model selection next."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('klarna': conda)",
   "name": "python381064bitklarnacondaf238ae83b93148ae9699955d68f1389c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}