{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f0643d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ZSCORE_CRITICAL_VALUE = 1.645 # equivalent to p-value = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874cf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = first_run\n",
    "except NameError:\n",
    "    first_run = True\n",
    "    os.chdir(os.getcwd().rsplit(\"/\", 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c28e2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d99414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = joblib.load(\"../data/train/preprocessed/train_features_labels.joblib.gz\")\n",
    "\n",
    "X_validation, y_validation = joblib.load(\"../data/train/preprocessed/validation_features_labels.joblib.gz\")"
   ]
  },
  {
   "source": [
    "# Hold your SMOTE for a moment\n",
    "\n",
    "SMOTE has become a ubiquitous way to handle imbalanced classes by oversampling the minority class. However, the fact that many of our features have low variance due to a lot of zero values, generating artificial samples from them can actually become quite counterproductive. Thus, we will experiment with both SMOTE and a custom undersampler that tries to capture most of the variance of the majority class. Whichever strategy yields better results for our baseline model will be the one we move forward with."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Custom undersampler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryUndersampler:\n",
    "    \n",
    "    def __init__(self, n_iterations: int=5, n_jobs: int=-1):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.highest_variance_sample = (None, None)\n",
    "        self.n_jobs = min(mp.cpu_count(), n_jobs) if n_jobs > 1 else mp.cpu_count()\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray, float, float, bool]:\n",
    "        \"\"\"Function to find a subsample of majority class (label) and its significance\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        Tuple[\n",
    "            X_subsample, numpy.ndarray: The selected subsample of the majority class\n",
    "            y_subsample, numpy.ndarray: The respective labels of the subsample\n",
    "            sample_variance, float: The subsample mean variance (mean of variance of each feature)\n",
    "            sample_variance_zscore, float: The bootstrap Z-score of the `sample_variance` from `n_iterations`,\n",
    "            is_sample_var_significantly_higher, bool: Whether the `sample_variance` is significantly higher than the bootstrap mean (p-value < 0.05)\n",
    "        ]\n",
    "        \"\"\"\n",
    "        self.majority_class = pd.value_counts(pd.Series(y)).index[0]\n",
    "        self.n_splits = math.floor(X.shape[0] / np.sum(y!=self.majority_class))\n",
    "        # split and select the sample with highest variance (decide how significant via bootstraping)\n",
    "        with mp.Pool(self.n_jobs) as pool:\n",
    "            bootstrap_samples = pool.starmap(\n",
    "                self.get_highest_variance_sample,\n",
    "                [(X[y==self.majority_class], y[y==self.majority_class], self.n_splits, idx) for idx in range(self.n_iterations)]\n",
    "            )\n",
    "        highest_zscore = sorted(stats.zscore(np.array(list(map(lambda tup: tup[-1], bootstrap_samples)))))[::-1][0]\n",
    "        is_sample_var_significantly_higher = highest_zscore > ZSCORE_CRITICAL_VALUE\n",
    "        highest_mean_var_sample = sorted(bootstrap_samples, key=lambda tup: tup[-1])[::-1][0]\n",
    "        return (*highest_mean_var_sample, highest_zscore, is_sample_var_significantly_higher)\n",
    "        \n",
    "\n",
    "    def get_highest_variance_sample(self, X: np.ndarray, y_label: np.ndarray, n_splits: int, random_state: int=42):\n",
    "        disjoint_samples = self._shuffle_split_observations(X, y_label, n_splits, random_state)\n",
    "        disjoint_samples_mean_var = map(self._get_mean_feature_variance, disjoint_samples)\n",
    "        highest_mean_var_sample = sorted(disjoint_samples_mean_var, key=lambda tup: tup[-1])[::-1][0]\n",
    "        return highest_mean_var_sample\n",
    "\n",
    "    def _shuffle_split_observations(self, X: np.ndarray, y_label: np.ndarray, n_splits: int, random_state: int=42) -> List:\n",
    "        \"\"\"Return a list of disjoint samples with the `y_label` concatenated at axis=1 (column)\"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        return np.array_split(np.random.permutation(np.concatenate((X, y_label.reshape(-1, 1)), axis=1)), n_splits)\n",
    "\n",
    "    def _get_mean_feature_variance(self, sample: np.ndarray) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "        X, y_label = sample[:, :-1], sample[:, -1]\n",
    "        mean_variance = np.mean(np.ma.var(X, axis=0))\n",
    "        return (X, y_label, mean_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryUndersampler().fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "name": "python388jvsc74a57bd09f119b1d3a8a63730ae7ee508102d23a56b995c1f2248036bd772c0398b7d40e",
   "display_name": "Python 3.8.8 64-bit ('klarna': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}