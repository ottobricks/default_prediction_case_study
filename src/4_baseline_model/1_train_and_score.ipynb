{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0643d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = first_run\n",
    "except NameError:\n",
    "    first_run = True\n",
    "    os.chdir(os.getcwd().rsplit(\"/\", 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c28e2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = joblib.load(\"../data/train/preprocessed/train_features_labels.joblib.gz\")\n",
    "\n",
    "X_validation, y_validation = joblib.load(\"../data/train/preprocessed/validation_features_labels.joblib.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3d80d",
   "metadata": {},
   "source": [
    "# Define baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "_ = joblib.dump(baseline, \"../ml_artifacts/baseline_model.joblib.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = baseline.predict_proba(X_validation)\n",
    "\n",
    "threshold_perf = pd.DataFrame(\n",
    "    [\n",
    "        (threshold, *confusion_matrix(y_validation, (prediction[:, 1] > threshold).astype(int)).ravel())\n",
    "        for threshold in np.arange(.05, .95, .05)\n",
    "    ],\n",
    "    columns=[\"threshold\", \"tn\", \"fp\", \"fn\", \"tp\"]\n",
    ").assign(\n",
    "    precision=lambda df: df[\"tp\"] / (df[\"tp\"] + df[\"fp\"]),\n",
    "    recall=lambda df: df[\"tp\"] / (df[\"tp\"] + df[\"fn\"]),\n",
    "    f1=lambda df: 2 * (df[\"precision\"] * df[\"recall\"]) / (df[\"precision\"] + df[\"recall\"])\n",
    ")\n",
    "\n",
    "threshold_perf.to_csv(\"../ml_artifacts/baseline_model_performance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(data, color='yellow'):\n",
    "    '''\n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    '''\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)\n",
    "\n",
    "\n",
    "threshold_perf.style.apply(\n",
    "    highlight_max, color='darkorange', subset=[\"precision\", \"recall\", 'f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "name": "python38864bitklarnaconda4ef8c56e5567458cb1bf905cc9704f70",
   "display_name": "Python 3.8.8 64-bit ('klarna': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}