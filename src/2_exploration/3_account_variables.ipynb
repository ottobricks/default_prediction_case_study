{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c76187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import scipy.cluster.hierarchy as spc\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382afc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = first_run\n",
    "except NameError:\n",
    "    first_run = True\n",
    "    os.chdir(os.getcwd().rsplit(\"/\", 1)[0])\n",
    "    from _aux import functions as func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6b81a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = (\n",
    "    pd.read_csv(\n",
    "        \"../data/train/X_train.csv\",\n",
    "        index_col=0,\n",
    "        usecols=[\n",
    "            \"row_id\",\n",
    "            \"account_amount_added_12_24m\",\n",
    "            \"sum_capital_paid_account_0_12m\",\n",
    "            \"sum_capital_paid_account_12_24m\",\n",
    "            \"account_incoming_debt_vs_paid_0_24m\",\n",
    "            \"num_unpaid_bills\",\n",
    "            \"sum_paid_inv_0_12m\",\n",
    "            \"max_paid_inv_0_12m\",\n",
    "            \"max_paid_inv_0_24m\",\n",
    "            \"num_active_inv\",\n",
    "            \"num_active_div_by_paid_inv_0_12m\",\n",
    "        ],\n",
    "    )\n",
    "    .join(pd.read_csv(\"../data/train/y_train.csv\", index_col=0))\n",
    "    .query(\"default == 1\")\n",
    ")\n",
    "\n",
    "not_default = (\n",
    "    pd.read_csv(\n",
    "        \"../data/train/X_train.csv\",\n",
    "        index_col=0,\n",
    "        usecols=[\n",
    "            \"row_id\",\n",
    "            \"account_amount_added_12_24m\",\n",
    "            \"sum_capital_paid_account_0_12m\",\n",
    "            \"sum_capital_paid_account_12_24m\",\n",
    "            \"account_incoming_debt_vs_paid_0_24m\",\n",
    "            \"num_unpaid_bills\",\n",
    "            \"sum_paid_inv_0_12m\",\n",
    "            \"max_paid_inv_0_12m\",\n",
    "            \"max_paid_inv_0_24m\",\n",
    "            \"num_active_inv\",\n",
    "            \"num_active_div_by_paid_inv_0_12m\",\n",
    "        ],\n",
    "    )\n",
    "    .join(pd.read_csv(\"../data/train/y_train.csv\", index_col=0))\n",
    "    .query(\"default == 0\")\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/train/X_train.csv\",\n",
    "    index_col=0,\n",
    ").join(pd.read_csv(\"../data/train/y_train.csv\", index_col=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74239b5",
   "metadata": {},
   "source": [
    "## Correlation between \"account\" variables\n",
    "\n",
    "As shown in our sanity profile report, account variables have high correlation amongst themselves mainly due to overlaping lookback windows for aggregation. The first thing we must do is choose one (or some) of them to represent the group, which can be achieved by correlation clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab255dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.concat([default, not_default]).corr()\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=corr.mask(mask),\n",
    "        x=corr.columns,\n",
    "        y=corr.columns,\n",
    "        colorscale=px.colors.diverging.RdBu,\n",
    "        zmin=-1,\n",
    "        zmax=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Correlation between 'account' variables\",\n",
    "    yaxis_autorange=\"reversed\",\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    "    width=1000,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "# fig.update_traces(opacity=0.6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdist = spc.distance.pdist(corr)\n",
    "linkage = spc.linkage(pdist, method=\"single\")\n",
    "idx = spc.fcluster(linkage, 0.5 * pdist.max(), \"distance\")\n",
    "\n",
    "columns = [default.columns.tolist()[i] for i in list((np.argsort(idx)))]\n",
    "clusterd_corr = pd.concat([default, not_default]).reindex(columns, axis=1).corr()\n",
    "\n",
    "mask = np.zeros_like(clusterd_corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "corr[\"default\"].to_frame(name=\"corr_with_label\").assign(cluster=idx).drop(\n",
    "    \"default\"\n",
    ").sort_values([\"cluster\", \"corr_with_label\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b4392",
   "metadata": {},
   "source": [
    "Despite our knowing that correlation is not equal to causation, the lack of proper time for exploration leads us to the not-so-ideal path of using correlation to exclude variables. At this time. we choose to analyze only the variable \"num_active_div_by_paid_inv_0_12m\" at the cost of probably losing some good insights.\n",
    "\n",
    "## 1. \"num_active_div_by_paid_inv_0_12m\"\n",
    "\n",
    "This variable has 22.8% of missing values and 48.7% of zero values, on top of some hard-hitting outliers.\n",
    "One behaviour this variable describes is whether the customer has had a good experience with us and has come back for more. On the flip side, users that have not finished paying their first invoice yet (in a 12 month span) are attributed NaN simple because division by zero is undefined. Hence, a good customer will get NaN on their first purchase, but also an ill-intentioned customer that executes multiple orders with no intention to pay them. Therefore, we choose to fill missing values with the number of active invoices so that the latter can become visible through this variable.\n",
    "\n",
    "Next, we look at how defaults are distributed across the categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617762cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"num_active_div_by_paid_inv_0_12m\"]].assign(\n",
    "    num_active_div_by_paid_inv_0_12m=df[\n",
    "        \"num_active_div_by_paid_inv_0_12m\"\n",
    "    ].combine_first(df[\"num_active_inv\"])\n",
    ").describe(np.append(np.arange(0.25, 1.0, 0.1), np.array([0.99])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71014735",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, var_profile = func.test_k_prop(\n",
    "    df[[\"default\"]]\n",
    "    .assign(\n",
    "        var=df[\"num_active_div_by_paid_inv_0_12m\"].combine_first(df[\"num_active_inv\"]),\n",
    "        bins_var=lambda frame: pd.cut(frame[\"var\"], range(-1, 10)),\n",
    "    )\n",
    "    .groupby(\"bins_var\")\n",
    "    .agg(\n",
    "        default=(\"default\", \"sum\"),\n",
    "        not_default=(\"default\", func.complement),\n",
    "        count=(\"default\", \"count\"),\n",
    "    )\n",
    "    .transform(lambda s: s.astype(int))\n",
    ")\n",
    "\n",
    "var_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e73cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=var_profile.reset_index().index.to_list(),\n",
    "        y=(var_profile[\"not_default\"] / var_profile[\"count\"]),\n",
    "        name=\"not_default\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=var_profile.reset_index().index.to_list(),\n",
    "        y=(var_profile[\"default\"] / var_profile[\"count\"]),\n",
    "        name=\"default\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of observations across 'num_active_div_by_paid_inv_0_12m' classes\",\n",
    "    barmode=\"relative\",\n",
    "    yaxis_title=\"Percentage\",\n",
    "    yaxis_tickformat=\"%\",\n",
    "    xaxis_title=\"Ordered Bins\",\n",
    "    xaxis_tickvals=[x for x in range(0, var_profile.shape[0])],\n",
    ")\n",
    "\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384b6a6",
   "metadata": {},
   "source": [
    "Let's take a look at the impact of our imputing by printing the number of new cases being considered for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df[[\"num_active_div_by_paid_inv_0_12m\", \"default\"]]\n",
    "    .assign(\n",
    "        # num_active_div_by_paid_inv_0_12m=df[\"num_active_div_by_paid_inv_0_12m\"].combine_first(df[\"num_active_inv\"]),\n",
    "        bins_var=pd.cut(df[\"num_active_div_by_paid_inv_0_12m\"], range(-1, 10))\n",
    "    )\n",
    "    .groupby(\"bins_var\")\n",
    "    .agg(\n",
    "        default=(\"default\", \"sum\"),\n",
    "        not_default=(\"default\", func.complement),\n",
    "        count=(\"default\", \"count\"),\n",
    "    )\n",
    "    .transform(lambda s: s.astype(int))\n",
    "    .assign(\n",
    "        default=lambda frame: var_profile[\"default\"] - frame[\"default\"],\n",
    "        not_default=lambda frame: var_profile[\"not_default\"] - frame[\"not_default\"],\n",
    "        count=lambda frame: var_profile[\"count\"] - frame[\"count\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c97fb",
   "metadata": {},
   "source": [
    "We see that most new observations due to imputing fall in the first bin (equals zero). However, percentagewise, the increase of default cases in categories that hold less observations is significantly higher, which indicates that our imputing strategy was indeed a good idea.\n",
    "\n",
    "Now, let's look at the impact of transforming this variable into a binary one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96422b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bool_var_profile = func.test_k_prop(\n",
    "    df[[\"default\"]]\n",
    "    .assign(\n",
    "        var=df[\"num_active_div_by_paid_inv_0_12m\"].combine_first(df[\"num_active_inv\"]),\n",
    "        bins_var=lambda frame: pd.cut(frame[\"var\"], [-1, 1, np.inf]),\n",
    "    )\n",
    "    .groupby(\"bins_var\")\n",
    "    .agg(\n",
    "        default=(\"default\", \"sum\"),\n",
    "        not_default=(\"default\", func.complement),\n",
    "        count=(\"default\", \"count\"),\n",
    "    )\n",
    "    .transform(lambda s: s.astype(int))\n",
    ")\n",
    "\n",
    "bool_var_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e4b81",
   "metadata": {},
   "source": [
    "It is interesting that the contamination rate in the \"bellow 1\" class is very close to the dataset as a whole (~0.014), but the \"above 1\" class gets a nearly 10-fold increase in its contamination (~.13). It seems that transforming this variable into boolean will still capture some of the \"default\" behaviour whilst reducing the trouble with the Curse of Dimensionality.\n",
    "\n",
    "How does this new variable correlate to the target label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1557b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"default\"]].assign(\n",
    "    var=df[\"num_active_div_by_paid_inv_0_12m\"].combine_first(df[\"num_active_inv\"]),\n",
    "    above_1=lambda frame: (frame[\"var\"] > 1).astype(float),\n",
    ").corr()[\"default\"].to_frame(name=\"corr_with_label\").drop(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9afd071",
   "metadata": {},
   "source": [
    "It is to be expected that reducing granularity will also reduce power. However, we must remind ourselves that correlation is not causation, and that the trade-off should be worth it. In conclusion, we decide to move forward with the boolean (above 1?) equivalent of the \"num_active_div_by_paid_inv_0_12m\" variable.\n",
    "\n",
    "Next, we look at \"archived\" variables."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('klarna': conda)",
   "name": "python388jvsc74a57bd09f119b1d3a8a63730ae7ee508102d23a56b995c1f2248036bd772c0398b7d40e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
